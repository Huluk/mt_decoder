#!/usr/bin/env python

import optparse
import sys
import os
import models
from collections import namedtuple, defaultdict

Inf = float("inf")

optparser = optparse.OptionParser()
optparser.add_option("-i", "--input", dest="input", default="data/input",
        help="File containing sentences to translate (default=data/input)")
optparser.add_option("-t", "--translation-model", dest="tm", default="data/tm",
        help="File containing translation model (default=data/tm)")
optparser.add_option("-l", "--language-model", dest="lm", default="data/lm",
        help="File containing ARPA-format bigram model (default=data/lm)")
optparser.add_option("-n", "--num_sentences", dest="num_sents", default=sys.maxint,
        type="int", help="Number of sentences to decode (default=no limit)")
optparser.add_option("-k", "--translations-per-phrase", dest="k", default=1, type="int",
        help="Limit on number of translations to consider per phrase (default=1)")
# optparser.add_option("-K", "--negative-cycle-cost", dest="K", default=1, type="float",
#         help="Cost subtracted for each step in a group cycle in AGTSP->STSP (default=1)")
optparser.add_option("-v", "--verbose", dest="verbose", action="store_true",
        default=False, help="Verbose mode (default=off)")
opts = optparser.parse_args()[0]

tm = models.TM(opts.tm, opts.k)
lm = models.LM(opts.lm) # assumes bigram model!
french = [tuple(line.strip().split()) for line in open(opts.input).readlines()[:opts.num_sents]]

# tm should translate unknown words as-is with probability 1
for word in set(sum(french,())):
    if (word,) not in tm:
        tm[(word,)] = [models.phrase(word, 0.0)]

Node = namedtuple("node", "logprob, word, word_index, i, j, biphrase")
MAX = 9999999

def translate(f):
    # make AGTSP
    nodes = [Node(0.0, '<s>', -1, -1, 0, models.phrase('', 0.0))]
    groups = defaultdict(list) # french word => [tsp_tuple, ...]
    groups[nodes[0].word] = [nodes[0]] # add startword group
    for i in xrange(len(f)):
        for j in xrange(i+1,len(f)+1):
            if f[i:j] in tm:
                for phrase in tm[f[i:j]]:
                    for (i_w, word) in enumerate(f[i:j]):
                        n = Node(phrase.logprob, word, i+i_w, i, j, phrase)
                        nodes.append(n)
                        groups[word] = groups[word] + [n]
                        # we can infer graph connection by index:
                        # connections from j to i' for group(j) != group(i')
                        # with edge cost: 1/Z * exp(lambda_k * h_k)
                        # with h = (p_lm, distortion(i',j), phrase.logprob)
                        # and distortion(x,y) = |x-y-1|
                        # connections from i to k for all k in [i+1,j]
                        # with edge cost: p_lm(eng'_first|eng_last) or 0
    # make ATSP, write LKH format
    outfile = open("data/tmp.lkh", 'w')
    outfile.write("NAME: %i\n" % hash(f))
    outfile.write("TYPE: ATSP\n")
    outfile.write("COMMENT: %s\n" % ' '.join(f))
    outfile.write("DIMENSION: %i\n" % len(nodes))
    outfile.write("EDGE_WEIGHT_TYPE: EXPLICIT\n")
    outfile.write("EDGE_WEIGHT_FORMAT: FULL_MATRIX\n")
    outfile.write("EDGE_WEIGHT_SECTION\n")
    sentence_length = len(f)
    # outfile.write(("\t%i" % MAX) + ("\t0"*len(nodes)) + "\n")
    for node1 in nodes:
        row = "\t"
        for node2 in nodes:
            weight = get_edge(groups, node1, node2, sentence_length)
            if type(weight) == float:
                weight = int(weight*100) # keep first 2 decimal places
            row += str(weight) + "\t"
        outfile.write(row+"\n")
    outfile.write("EOF\n")
    outfile.close()
    os.system("./LKH lkh_param > /dev/null")
    best_tour = read_best_tour('data/tmp_best_tour')
    current_word = None
    translation = []
    for i in best_tour:
        node = nodes[i-1]
        if node.word != current_word:
            current_word = node.word
            phrase = node.biphrase.english
            if not phrase in translation:
                translation.append(phrase)
    return ' '.join(translation)

def get_edge(groups, node1, node2, sentence_length):
    if node1 == node2:
        pass
    elif groups[node1.word] == groups[node2.word]:
        i1 = groups[node1.word].index(node1)
        i2 = groups[node2.word].index(node2)
        if i2 == (i1+1) % len(groups[node1.word]):
            return -MAX # -K
    else:
        group = groups[node1.word]
        i = group.index(node1)
        ref_node = group[(i + 1) % len(group)]
        if ref_node.biphrase == node2.biphrase:
            if node2.word_index == ref_node.word_index + 1:
                return 0
        elif node2 in groups[0]:
            if ref_node in groups[-1]:
                # going from end to start
                return 0
        elif node2.word_index == node2.i and ref_node.word_index + 1 == ref_node.j:
            distortion = -float(abs(node2.i - ref_node.j - 1)) / sentence_length
            if ref_node in groups[0]:
                lm_probs = 0.0
            else:
                prev_word = ref_node.biphrase.english.split()[-1]
                lm_probs = get_lm_probs(prev_word, node2.biphrase.english.split())
            return -(node2.logprob + lm_probs + distortion)
    return MAX

def read_best_tour(path):
    infile = open(path)
    best_tour = [int(line) for line in infile.readlines() # TODO adjust index 
            if line.rstrip().isdigit()]
    start_index = best_tour.index(1)
    best_tour = best_tour[(start_index+1):] + best_tour[0:start_index]
    infile.close()
    return best_tour

def get_lm_probs(start_word, words):
    lm_state = (start_word,) if start_word in lm.table else ()
    logprob = 0
    for word in words:
        (lm_state, word_logprob) = lm.score(lm_state, word)
        logprob += word_logprob
        lm_state = (word,)
    return logprob

for f in french:
    print translate(f)
