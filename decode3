#!/usr/bin/env python

import optparse
import sys
import models
from collections import namedtuple, defaultdict

Inf = float("inf")

optparser = optparse.OptionParser()
optparser.add_option("-i", "--input", dest="input", default="data/input",
        help="File containing sentences to translate (default=data/input)")
optparser.add_option("-t", "--translation-model", dest="tm", default="data/tm",
        help="File containing translation model (default=data/tm)")
optparser.add_option("-l", "--language-model", dest="lm", default="data/lm",
        help="File containing ARPA-format bigram model (default=data/lm)")
optparser.add_option("-n", "--num_sentences", dest="num_sents", default=sys.maxint,
        type="int", help="Number of sentences to decode (default=no limit)")
optparser.add_option("-k", "--translations-per-phrase", dest="k", default=1, type="int",
        help="Limit on number of translations to consider per phrase (default=1)")
# optparser.add_option("-K", "--negative-cycle-cost", dest="K", default=1, type="float",
#         help="Cost subtracted for each step in a group cycle in AGTSP->STSP (default=1)")
optparser.add_option("-v", "--verbose", dest="verbose", action="store_true",
        default=False, help="Verbose mode (default=off)")
opts = optparser.parse_args()[0]

tm = models.TM(opts.tm, opts.k)
lm = models.LM(opts.lm) # assumes bigram model!
french = [tuple(line.strip().split()) for line in open(opts.input).readlines()[:opts.num_sents]]

# tm should translate unknown words as-is with probability 1
for word in set(sum(french,())):
    if (word,) not in tm:
        tm[(word,)] = [models.phrase(word, 0.0)]

node = namedtuple("node", "logprob, word, word_index, i, j, biphrase")

def run(f):
    # make AGTSP
    nodes = []
    groups = defaultdict(list) # french word => [tsp_tuple, ...]
    for i in xrange(len(f)):
        for j in xrange(i+1,len(f)+1):
            if f[i:j] in tm:
                for phrase in tm[f[i:j]]:
                    for (i_w, word) in enumerate(f[i:j]):
                        n = node(phrase.logprob, word, i+i_w, i, j, phrase)
                        nodes.append(n)
                        groups[word] = groups[word] + [n]
                        # we can infer graph connection by index:
                        # connections from j to i' for group(j) != group(i')
                        # with edge cost: 1/Z * exp(lambda_k * h_k)
                        # with h = (p_lm, distortion(i',j), phrase.logprob)
                        # and distortion(x,y) = |x-y-1|
                        # connections from i to k for all k in [i+1,j]
                        # with edge cost: p_lm(eng'_first|eng_last) or 0
    # make ATSP, write LKH format
    print "NAME: %i" % hash(f)
    print "TYPE: ATSP"
    print "COMMENT: %s" % ' '.join(f)
    print "DIMENSION: %i" % len(nodes)
    print "EDGE_WEIGHT_TYPE: EXPLICIT"
    print "EDGE_WEIGHT_FORMAT: FULL_MATRIX"
    print "EDGE_WEIGHT_SECTION"
    sentence_length = len(f)
    # TODO extend by artificial start and end nodes
    for node1 in nodes:
        row = "\t"
        for node2 in nodes:
            weight = get_edge(groups, node1, node2, sentence_length)
            if type(weight) == float:
                weight = int(weight*100) # keep first 2 decimal places
            row += str(weight) + "\t"
            # if not weight is None:
            #     print weight
        print row
    print "EOF"

def get_edge(group, node1, node2, sentence_length):
    MAX = 9999999
    if node1 == node2:
        pass
    elif group[node1.word] == group[node2.word]:
        i1 = group[node1.word].index(node1)
        i2 = group[node2.word].index(node2)
        if i2 == i1+1 or (i1 == len(group[node1.word]) and i2 == 0):
            return -MAX # -K
    elif node1.biphrase == node2.biphrase:
        if node2.word_index == node1.word_index + 1:
            return 0
    elif node2.word_index == node2.i and node1.word_index + 1 == node1.j:
        distortion = -float(abs(node2.i - node1.j - 1)) / sentence_length
        prev_word = node1.biphrase.english.split()[-1]
        lm_probs = get_lm_probs(prev_word, node2.biphrase.english.split())
        return -(node2.logprob + lm_probs + distortion)
    return MAX

def get_lm_probs(start_word, words):
    lm_state = (start_word,) if start_word in lm.table else ()
    logprob = 0
    for word in words:
        (lm_state, word_logprob) = lm.score(lm_state, word)
        logprob += word_logprob
        lm_state = (word,)
    return logprob

for f in french:
    run(f)
